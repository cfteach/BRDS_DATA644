
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Building MCMC from scratch &#8212; Bayesian Reasoning in Data Science (DATA 644)</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="_static/wm_vertical_single_line_full_color.png"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Gaussian Processes" href="Gaussian_Processes.html" />
    <link rel="prev" title="Bayes Factors" href="Bayes_Factors.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/wm_vertical_single_line_full_color.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Bayesian Reasoning in Data Science (DATA 644)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Bayesian Reasoning in Data Science (PhD Course)
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Lectures (integrate with notebooks below)
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://docs.google.com/presentation/d/1uXlxQoqseWwwurtU-HSbqEz6EvE-r4ZSPorJU8kmFgw/edit?usp=sharing">
   Bayes Theorem, priors, likelihood, posterior, distributions - Lec 1 (1/25/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://docs.google.com/presentation/d/1A46CUs7thqx5qPV91fdywdkl0nQx_PWhokTif0Rmf_8/edit?usp=sharing">
   Bayes Theorem, subjective and objective interpretations of probability, Exercises - Lec 2 (1/30/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://docs.google.com/presentation/d/1r1Np-VjDTCLCmaynoOBaCel3W40bZvj9lQBlY6zfggc/edit?usp=sharing">
   Thinking Probabilistically, Causes and Effects , True and Measured; Credible Intervals, ROPE, HDI - Lec 3 (2/1/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://docs.google.com/presentation/d/1_GlPlOWiB9HGNph6jKFfHdZjP7tm70WiqsmEZeUcC-E/edit?usp=sharing">
   Inference and Intro to Probabilistic Programming, PyMC; Credible Intervals, ROPE, HDI - Lec 4 (2/6/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://docs.google.com/presentation/d/1xwxp7steeZfhyNR1OAtRSWR1Qnx0OKVfA0WvpHNR-CM/edit?usp=sharing">
   Inference and Intro to Probabilistic Programming, PyMC; Credible Intervals, ROPE, HDI - Lec 5 (2/8/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://docs.google.com/presentation/d/1J0j8Y3S0gcGLL-9JsUuQEpZ1J-YU6bZKM_GJ4M_7_jA/edit?usp=sharing">
   Gaussian Inference; t-Student; Update of Beliefs - Lec 6 (2/13/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://docs.google.com/presentation/d/1nFAnk_s-SVPVRUs-r4MdxR-KTCknRhwJwHQpgoiqZHk/edit?usp=sharing">
   Bayesian Linear Regression; Robust Regression - Lec 7 (2/15/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://docs.google.com/presentation/d/1Na_htl6xFF9Td-giuBGRjnsdZUX8pVnq0wCS7qzk9WA/edit?usp=sharing">
   Bayesian Polynomial Regression, Posterior Predictive Checks - Lec 8 (2/20/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://docs.google.com/presentation/d/1JqfptaCn1qGk18gEGvfnk3GoO3U5Xtz1nNtJh1rBX5U/edit?usp=sharing">
   Bayesian Logistic Regression and Softmax - Lec 9 (2/22/2024), Lec 10 (2/27/2024), Lec 11 (2/29/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://docs.google.com/presentation/d/1oFcM9T3RIDgvRShnSzEsvqOCha8OH8c_vd60n7cLHOI/edit?usp=sharing">
   Bayesian Model Comparison and Information Criteria -  Lec 12 (3/5/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://docs.google.com/presentation/d/1DMbpCpt4qUHdHjZ_VOB2UvUiavL2-BPU-4EvGjDBL68/edit?usp=sharing">
   Bayes Factors, sequential MC - Lec 13 (3/7/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://docs.google.com/presentation/d/17YmhZNgNNIIo3BqnVWTs8GHlTAo1eO6I_M-_yM_moZk/edit?usp=sharing">
   MCMC from scratch - Lec 14 (3/19/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://docs.google.com/presentation/d/1wC-PCgw1IC_Vrx31vbdd_soOEfH9j4Q-ZS8QuFvpHYk/edit?usp=sharing">
   Intro to Gaussian Processes - Lec 15 (3/21/2024), Lec 16 (3/26/2024), Lec 17 (3/28/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://docs.google.com/presentation/d/1mMOooI65xibJ1lhYX1_pqaMZrHYOq-nUTIihUBpNmFE/edit?usp=sharing">
   Introduction to Bayes Networks - Lec 20 (4/9/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://docs.google.com/presentation/d/1MHynfX4iBHDpwv0vFdhAt5QMBz2WFKu9OQMcG3JU3qs/edit?usp=sharing">
   Introduction to Bayesian Neural Networks - Lec 22 (4/16/2024)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Notebooks
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="MontyHall_MC.html">
   Bayes Theorem (2/1/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Intro_Bayes.html">
   Thinking Probabilistically (2/1/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Intro_PyMC4.html">
   Intro to Probabilistic Programming (2/6/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Intro_MCMC.html">
   An (Over-)Simplified Intro to MCMC (2/8/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Gaussian_Inferences.html">
   Bayesian Inference with Gaussian and t-Student models, update of beliefs (2/13/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Bayesian_Linear_Regression2.html">
   Bayesian Linear Regression; Robust Inference (2/15/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Bayesian_Polynomial_Regression.html">
   Bayesian Polynomial Regression, Posterior Predictive Checks and Comparison with Observations (2/20/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Bayesian_Logistic_Regression.html">
   Bayesian Logistic Regression (2/22/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Bayesian_Softmax.html">
   Bayesian Softmax (2/27/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Model_Comparison.html">
   Model Comparison, Information Criteria (3/5/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Bayes_Factors.html">
   Model Comparison, Bayes Factors (3/7/2024)
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Building MCMC from scratch; a closer look at samplers (3/19/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Gaussian_Processes.html">
   Gaussian Processes (3/26/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="moo_BO_3obj.html">
   Multi-Objective Optimization (4/4/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Bayes_Nets_2.html">
   Bayesian Networks (4/9/2024) and (4/11/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Bayesian_Neural_Network.html">
   Bayesian Neural Networks (4/16/2024)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="BCNN_4.html">
   Bayesian Convolutional Neural Network (4/25/2024)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Assignments
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://drive.google.com/file/d/1WRx6z70xiTeizudRDfY5EIrVRG893CcS/view?usp=sharing">
   Assignment 1 - PDF (Questions 1 and 3)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Sol_assignment1.html">
   Assignment 1 - notebook (Question 2)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Sol_assignment2.html">
   Assignment 2 - notebook (All Questions)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Sol_assignment3.html">
   Assignment 3 - notebook (All Questions)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Question and Answers
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://docs.google.com/document/d/1D3qSpwsDQE9I44s9d9YiSepVw4gPmae0g7DjGtD4xbA/edit?usp=sharing">
   Q&amp;A Shared Google Doc (used in class)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Projects
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://cfteach.github.io/pyscr/">
   Mini-project (pyscript + PyMC)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://cfteach.github.io/brds/bayesian_A_B_testing_mini_project.html">
   Bayesian A/B testing (pyscript) by R. Gupta, BRDS class 2022
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Additional resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="mcmc_examples.html">
   MCMC examples
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="referencesmd.html">
   References
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/cfteach/BRDS_DATA644/main?urlpath=tree/notebooks/MCMC_from_scratch_all.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="http://jupyterhub.wm.edu/hub/user-redirect/git-pull?repo=https://github.com/cfteach/BRDS_DATA644&urlpath=tree/BRDS_DATA644/notebooks/MCMC_from_scratch_all.ipynb&branch=main"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on JupyterHub"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_jupyterhub.svg">
  </span>
<span class="headerbtn__text-container">JupyterHub</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/cfteach/BRDS_DATA644/blob/main/notebooks/MCMC_from_scratch_all.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/cfteach/BRDS_DATA644"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/cfteach/BRDS_DATA644/issues/new?title=Issue%20on%20page%20%2FMCMC_from_scratch_all.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/MCMC_from_scratch_all.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#monte-carlo">
   Monte Carlo
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#metropolis-hastings">
   Metropolis-Hastings
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-algorithm">
     The Algorithm:
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#metropolis-hastings-vs-hamiltonian-monte-carlo-nuts-a-simplified-introduction">
   Metropolis-Hastings vs Hamiltonian Monte Carlo / NUTS: A simplified introduction
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hamiltonian-mechanics-in-hmc">
     Hamiltonian Mechanics in HMC
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#leapfrog-integration">
     Leapfrog Integration
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tuning-hmc">
     Tuning HMC
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Building MCMC from scratch</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#monte-carlo">
   Monte Carlo
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#metropolis-hastings">
   Metropolis-Hastings
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-algorithm">
     The Algorithm:
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#metropolis-hastings-vs-hamiltonian-monte-carlo-nuts-a-simplified-introduction">
   Metropolis-Hastings vs Hamiltonian Monte Carlo / NUTS: A simplified introduction
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hamiltonian-mechanics-in-hmc">
     Hamiltonian Mechanics in HMC
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#leapfrog-integration">
     Leapfrog Integration
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tuning-hmc">
     Tuning HMC
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="building-mcmc-from-scratch">
<h1>Building MCMC from scratch<a class="headerlink" href="#building-mcmc-from-scratch" title="Permalink to this headline">#</a></h1>
<section id="monte-carlo">
<h2>Monte Carlo<a class="headerlink" href="#monte-carlo" title="Permalink to this headline">#</a></h2>
<p>“<a class="reference external" href="https://en.wikipedia.org/wiki/Monte_Carlo_method">Monte Carlo methods, or Monte Carlo experiments</a>, are a broad class of computational algorithms that rely on repeated random sampling to obtain numerical results. The underlying concept is to use randomness to solve problems that might be deterministic in principle.”</p>
<p>Simple example: calculate <span class="math notranslate nohighlight">\(\pi\)</span> with Monte Carlo methods</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="c1"># generate uniformly random points within a square of radius 2R with R=1</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">5000</span> <span class="c1">#points</span>

<span class="n">points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">inside</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">points</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span> <span class="n">points</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">&lt;</span><span class="mi">1</span><span class="p">)</span>

<span class="n">res</span> <span class="o">=</span> <span class="n">inside</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="n">ratio</span> <span class="o">=</span> <span class="n">res</span> <span class="o">/</span> <span class="n">N</span>

<span class="n">approx_pi</span> <span class="o">=</span> <span class="mi">4</span><span class="o">*</span><span class="n">ratio</span>

<span class="nb">print</span><span class="p">(</span><span class="n">approx_pi</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.1632
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">figure</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Figure size 1200x1200 with 0 Axes&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">points</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">points</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">points</span><span class="p">[</span><span class="n">inside</span><span class="p">][:,</span><span class="mi">0</span><span class="p">],</span><span class="n">points</span><span class="p">[</span><span class="n">inside</span><span class="p">][:,</span><span class="mi">1</span><span class="p">],</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">1.25</span><span class="p">,</span><span class="mf">1.25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">1.25</span><span class="p">,</span><span class="mf">1.25</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(-1.25, 1.25)
</pre></div>
</div>
<img alt="_images/MCMC_from_scratch_all_8_1.png" src="_images/MCMC_from_scratch_all_8_1.png" />
</div>
</div>
</section>
<hr class="docutils" />
<section id="metropolis-hastings">
<h2>Metropolis-Hastings<a class="headerlink" href="#metropolis-hastings" title="Permalink to this headline">#</a></h2>
<p>“A <a class="reference external" href="https://en.wikipedia.org/wiki/Markov_chain">Markov chain or Markov process</a> is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. Informally, this may be thought of as, <em>‘What happens next depends only on the state of affairs now’</em>.”</p>
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/2b/Markovkate_01.svg/260px-Markovkate_01.svg.png" alt="alternatetext">
<p><em>The defining characteristic of a Markov chain is that no matter how the process arrived at its present state, the possible future states are fixed. In other words, the probability of transitioning to any particular state is dependent solely on the current state and hence they are referred to a <a class="reference external" href="https://wiki.ubc.ca/Course:CPSC522/Markov_Chains">“Memoryless”</a>. Markov Chains can be modeled as a finite state machine that shows how a system transitions from one state to another and with what probability.</em></p>
<p>The condition of <strong>detailed balance</strong> of a Markov chain says that we should move in a reversible way, meaning the probability of moving from state <span class="math notranslate nohighlight">\(i\)</span> to state <span class="math notranslate nohighlight">\(j\)</span> is the same of moving from state <span class="math notranslate nohighlight">\(j\)</span> to state <span class="math notranslate nohighlight">\(i\)</span>, or <span class="math notranslate nohighlight">\(\pi_{i}P_{ij}=\pi_{j}P_{ji}\)</span>. This condition is used as a guide to design our MCMC, see later.</p>
<p>“<a class="reference external" href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo">Markov chain Monte Carlo (MCMC)</a> methods comprise a class of algorithms for sampling from a probability distribution. By constructing a Markov chain that has the desired distribution as its equilibrium distribution, one can obtain a sample of the desired distribution by recording states from the chain.”</p>
<p>MCMC algorithms are all constructed to have a stationary distribution. However, we require extra conditions to ensure that they converge to such distribution. Please see concept of <a class="reference external" href="https://projecteuclid.org/journals/annals-of-applied-probability/volume-16/issue-3/On-the-ergodicity-properties-of-some-adaptive-MCMC-algorithms/10.1214/105051606000000286.full">ergodicity</a>, starting from a simpler definition <a class="reference external" href="https://en.wikipedia.org/wiki/Ergodicity">here</a>.</p>
<section id="the-algorithm">
<h3>The Algorithm:<a class="headerlink" href="#the-algorithm" title="Permalink to this headline">#</a></h3>
<ol class="simple">
<li><p>Choose an initial value for the parameter <span class="math notranslate nohighlight">\(x_i\)</span></p></li>
<li><p>Choose a new <span class="math notranslate nohighlight">\(x_{i+1}\)</span> by sampling from an easy-to-sample PROPOSAL (aka TRIAL) DISTRIBUTION (dubbed <span class="math notranslate nohighlight">\(q\)</span>) that allow to do the transition from <span class="math notranslate nohighlight">\(q(x_{i+1}|x_{i})\)</span>. This is a sort of perturbation from the state <span class="math notranslate nohighlight">\(x_{i}\)</span> to <span class="math notranslate nohighlight">\(x_{i+1}\)</span></p></li>
<li><p>Accept the new proposed state? The Metropolis-Hastings criterion is:</p></li>
</ol>
<p><span class="math notranslate nohighlight">\(p(x_{i+1}|x_{i}) = min\{1,\frac{p(x_{i+1})q(x_{i}|x_{i+1})}{p(x_{i})q(x_{i+1}|x_{i})}\}\)</span></p>
<ol>
<li><p>If the probability of point 3 is larger than the value taken from a uniform distribution between [0,1], then accept the new state; otherwise, remain in the old state</p></li>
<li><p>Iterate from step 2 until we have “enough” samples.</p>
<p>— we will see later convergence criteria —</p>
</li>
</ol>
<p>Notice that if <span class="math notranslate nohighlight">\(q(x_{i}|x_{i+1})=q(x_{i+1}|x_{i})\)</span> (detailed balance) we get the Metropolis criterion (drop the Hastings part), and get:</p>
<p><span class="math notranslate nohighlight">\(p(x_{i+1}|x_{i}) = min\{1,\frac{p(x_{i+1})}{p(x_{i})}\}\)</span></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>  take a minute to make sense of this formula
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">metropolis</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">draws</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>

  <span class="n">trace</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">draws</span><span class="p">)</span>
  <span class="n">old_x</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="c1">#starting point</span>
  <span class="n">old_prob</span> <span class="o">=</span> <span class="n">func</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">old_x</span><span class="p">)</span>

  <span class="n">delta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="n">draws</span><span class="p">)</span> <span class="c1">#trial distribution</span>

  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">draws</span><span class="p">):</span>
    <span class="n">new_x</span> <span class="o">=</span> <span class="n">old_x</span> <span class="o">+</span> <span class="n">delta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">new_prob</span> <span class="o">=</span> <span class="n">func</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">new_x</span><span class="p">)</span>
    <span class="n">acceptance</span> <span class="o">=</span> <span class="n">new_prob</span><span class="o">/</span><span class="n">old_prob</span>

    <span class="k">if</span><span class="p">(</span><span class="n">acceptance</span><span class="o">&gt;</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)):</span>
      <span class="n">trace</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_x</span>
      <span class="n">old_x</span> <span class="o">=</span> <span class="n">new_x</span>
      <span class="n">old_prob</span> <span class="o">=</span> <span class="n">new_prob</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">trace</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">old_x</span> <span class="c1"># remain in the same state</span>

  <span class="k">return</span> <span class="n">trace</span>
</pre></div>
</div>
</div>
</div>
<p>Now another (very) simple problem. MCMC of a beta function (yes, we already know its pdf… if you are thinking ‘what’s the point?’, we are just introducing the mechanism of the MCMC sampling with a concrete simple implementation).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="c1">#--- results from mcmc</span>
<span class="n">func</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">trace</span> <span class="o">=</span> <span class="n">metropolis</span><span class="p">(</span><span class="n">func</span><span class="o">=</span><span class="n">func</span><span class="p">)</span>
<span class="c1">#--- for plotting the true pdf for comparison</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span><span class="mf">0.99</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">func</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="c1">#---</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="s1">&#39;C1&#39;</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;True Distribution&#39;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="n">trace</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">],</span><span class="n">bins</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Estimated Distribution&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;pdf(x)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;ipython-input-37-d9c755d2d8e9&gt;:12: UserWarning: color is redundantly defined by the &#39;color&#39; keyword argument and the fmt string &quot;C1&quot; (-&gt; color=(1.0, 0.4980392156862745, 0.054901960784313725, 1.0)). The keyword argument will take precedence.
  plt.plot(x,y,&#39;C1&#39;,lw=3,label=&#39;True Distribution&#39;,color=&#39;red&#39;)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x78180691b220&gt;
</pre></div>
</div>
<img alt="_images/MCMC_from_scratch_all_16_2.png" src="_images/MCMC_from_scratch_all_16_2.png" />
</div>
</div>
<p>What is Bayesian in all this?
Make connection to what we have done so far for inferential problems using PyMC. (Notes in class)</p>
<p>After remembering this connection (real-world problems, not like the above), hopefully you are now fully appreciating the power of MCMC…</p>
</section>
</section>
<hr class="docutils" />
<section id="metropolis-hastings-vs-hamiltonian-monte-carlo-nuts-a-simplified-introduction">
<h2>Metropolis-Hastings vs Hamiltonian Monte Carlo / NUTS: A simplified introduction<a class="headerlink" href="#metropolis-hastings-vs-hamiltonian-monte-carlo-nuts-a-simplified-introduction" title="Permalink to this headline">#</a></h2>
<p>NUTS paper <a class="reference external" href="http://www.stat.columbia.edu/~gelman/research/published/nuts.pdf">http://www.stat.columbia.edu/~gelman/research/published/nuts.pdf</a></p>
<p>Hamiltonian Monte Carlo (HMC) enhances the Metropolis Hastings (MH) algorithm by incorporating a more complex proposal distribution informed by Hamiltonian mechanics. Unlike MH, which relies on random walks and becomes inefficient in high-dimensional spaces, HMC facilitates more efficient exploration through dynamically sized jumps based on the local (negative log) likelihood landscape.</p>
<section id="hamiltonian-mechanics-in-hmc">
<h3>Hamiltonian Mechanics in HMC<a class="headerlink" href="#hamiltonian-mechanics-in-hmc" title="Permalink to this headline">#</a></h3>
<p>HMC uses differential equations from Hamiltonian mechanics to relate position (<code class="docutils literal notranslate"><span class="pre">Q</span></code>) and momentum (<code class="docutils literal notranslate"><span class="pre">P</span></code>), allowing for adaptive jumps in the parameter space. These jumps are guided by:</p>
<ul class="simple">
<li><p><strong>Potential Energy (<code class="docutils literal notranslate"><span class="pre">V</span></code>)</strong>, derived from the negative log-likelihood, indicating the model’s fit.</p></li>
<li><p><strong>Kinetic Energy (<code class="docutils literal notranslate"><span class="pre">K</span></code>)</strong>, associated with the momentum variables, reflecting movement through the parameter space.</p></li>
</ul>
<p>The core of HMC lies in its use of Hamilton’s equations to simulate the dynamics of a system:</p>
<ul class="simple">
<li><p><strong>Position Update</strong>: <span class="math notranslate nohighlight">\(( \frac{dQ}{dT} = P ) \)</span></p></li>
<li><p><strong>Momentum Update</strong>: <span class="math notranslate nohighlight">\(( \frac{dP}{dT} = -\frac{dV}{dQ} )\)</span></p></li>
</ul>
</section>
<section id="leapfrog-integration">
<h3>Leapfrog Integration<a class="headerlink" href="#leapfrog-integration" title="Permalink to this headline">#</a></h3>
<p>To approximate these dynamics, HMC employs the leapfrog integration method, updating position and momentum iteratively to navigate the probability distribution efficiently. This method allows for larger jumps when far from high likelihood regions and smaller, more precise jumps when near, optimizing the exploration of the distribution.</p>
<p>Momentum kicks, analogous to MH’s proposal distribution, enable exploration of different likelihood levels. Correcting for the asymmetric nature of these proposals, HMC ensures reversibility by comparing the starting and ending states, with an adjustment for kinetic energy, thereby maintaining proposal distribution symmetry.</p>
</section>
<section id="tuning-hmc">
<h3>Tuning HMC<a class="headerlink" href="#tuning-hmc" title="Permalink to this headline">#</a></h3>
<p>Choosing appropriate step sizes and integration lengths is crucial for HMC’s efficiency but challenging. The No U-Turn Sampler (NUTS) addresses this by automatically adjusting these parameters, making it a more commonly used variant in practice.</p>
<p>HMC’s advantage lies in its principled approach to exploring complex distributions, leveraging Hamiltonian mechanics to navigate the parameter space more effectively than traditional MH sampling. This methodology allows for more representative sampling from high-dimensional distributions, addressing the limitations of random walk strategies.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">st</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">normal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;mu&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;sigma&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">numerator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="p">((</span><span class="n">x</span><span class="o">-</span><span class="n">mu</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
    <span class="n">denominator</span> <span class="o">=</span> <span class="n">sigma</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">numerator</span><span class="o">/</span><span class="n">denominator</span>

<span class="k">def</span> <span class="nf">generalized_neg_log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the negative log probability using a general distribution function.</span>
<span class="sd">    The &#39;func&#39; argument expects a distribution function, followed by its parameters.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">probability</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probability</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">HMC</span><span class="p">(</span><span class="n">mu</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span><span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span><span class="n">path_len</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">step_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span><span class="n">initial_position</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="mi">1_000</span><span class="p">):</span>
    <span class="c1"># setup</span>
    <span class="n">steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">path_len</span><span class="o">/</span><span class="n">step_size</span><span class="p">)</span> <span class="c1"># path_len and step_size are tricky parameters to tune...</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">initial_position</span><span class="p">]</span>
    <span class="n">momentum_dist</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">dVdQfun</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">tmpq</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="p">(</span><span class="n">tmpq</span><span class="o">-</span><span class="n">mu</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># gradient of PDF wrt position (e.g., q0 is the initial) aka potential energy wrt position</span>

    <span class="c1"># generate samples</span>
    <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">q0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">q1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">q0</span><span class="p">)</span>
        <span class="n">p0</span> <span class="o">=</span> <span class="n">momentum_dist</span><span class="o">.</span><span class="n">rvs</span><span class="p">()</span>
        <span class="n">p1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">p0</span><span class="p">)</span>
        <span class="c1"># momentum; this is an auxiliary variable.</span>
        <span class="c1"># It does not correspond to model parameters, i.e., it is specified independently of the model&#39;s parameters. It typically follows a Gaussian distribution,</span>

        <span class="n">dVdQ</span> <span class="o">=</span> <span class="n">dVdQfun</span><span class="p">(</span><span class="n">q0</span><span class="p">)</span>

        <span class="c1"># leapfrog integration begin</span>
        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
            <span class="n">p1</span> <span class="o">+=</span> <span class="n">step_size</span><span class="o">*</span><span class="n">dVdQ</span><span class="o">/</span><span class="mi">2</span> <span class="c1"># as potential energy increases, kinetic energy decreases, half-step</span>
            <span class="n">q1</span> <span class="o">+=</span> <span class="n">step_size</span><span class="o">*</span><span class="n">p1</span> <span class="c1"># position increases as function of momentum</span>
            <span class="n">p1</span> <span class="o">+=</span> <span class="n">step_size</span><span class="o">*</span><span class="n">dVdQfun</span><span class="p">(</span><span class="n">q1</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span> <span class="c1"># second half-step &quot;leapfrog&quot; update to momentum</span>
            <span class="n">dVdQ</span> <span class="o">=</span> <span class="n">dVdQfun</span><span class="p">(</span><span class="n">q1</span><span class="p">)</span>
        <span class="c1"># leapfrog integration end</span>
        <span class="n">p1</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">p1</span> <span class="c1">#flip momentum for reversibility</span>

        <span class="c1">#metropolis acceptance</span>
        <span class="c1">#q0_nlp = neg_log_prob(x=q0,mu=mu,sigma=sigma)</span>
        <span class="n">q0_nlp</span> <span class="o">=</span> <span class="n">generalized_neg_log_prob</span><span class="p">(</span><span class="n">q0</span><span class="p">,</span> <span class="n">normal</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
        <span class="n">q1_nlp</span> <span class="o">=</span> <span class="n">generalized_neg_log_prob</span><span class="p">(</span><span class="n">q1</span><span class="p">,</span> <span class="n">normal</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>

        <span class="n">p0_nlp</span> <span class="o">=</span> <span class="n">generalized_neg_log_prob</span><span class="p">(</span><span class="n">p0</span><span class="p">,</span> <span class="n">normal</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">p1_nlp</span> <span class="o">=</span> <span class="n">generalized_neg_log_prob</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span> <span class="n">normal</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>


        <span class="c1"># Account for negatives AND log(probabiltiies)...</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">q0_nlp</span> <span class="o">-</span> <span class="n">q1_nlp</span> <span class="c1"># P(q0)/P(q0)</span>
        <span class="n">adjustment</span> <span class="o">=</span> <span class="n">p0_nlp</span> <span class="o">-</span> <span class="n">p1_nlp</span> <span class="c1"># P(p1)/P(p1)</span>
        <span class="n">acceptance</span> <span class="o">=</span> <span class="n">target</span> <span class="o">+</span> <span class="n">adjustment</span> <span class="c1"># [P(q1)*P(p1)]/[P(q0)*P(p0)]</span>

        <span class="n">event</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">event</span> <span class="o">&lt;=</span> <span class="n">acceptance</span><span class="p">:</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">q1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">q0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">samples</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">mu</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">trial</span> <span class="o">=</span> <span class="n">HMC</span><span class="p">(</span><span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span><span class="n">path_len</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">step_size</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20000</span><span class="p">)</span> <span class="c1">#note the step_size and path_len parameters</span>

<span class="n">lines</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">10_000</span><span class="p">)</span>
<span class="n">normal_curve</span> <span class="o">=</span> <span class="p">[</span><span class="n">normal</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">l</span><span class="p">,</span><span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lines</span><span class="p">,</span><span class="n">normal_curve</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">trial</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/MCMC_from_scratch_all_22_0.png" src="_images/MCMC_from_scratch_all_22_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mu</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">trial</span> <span class="o">=</span> <span class="n">HMC</span><span class="p">(</span><span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span><span class="n">path_len</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span><span class="n">step_size</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span> <span class="c1">#note the change in step_size and path_len parameters...</span>

<span class="n">lines</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">10_000</span><span class="p">)</span>
<span class="n">normal_curve</span> <span class="o">=</span> <span class="p">[</span><span class="n">normal</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">l</span><span class="p">,</span><span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lines</span><span class="p">,</span><span class="n">normal_curve</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">trial</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/MCMC_from_scratch_all_24_0.png" src="_images/MCMC_from_scratch_all_24_0.png" />
</div>
</div>
<p>The code above implements a basic form of Hamiltonian Monte Carlo (HMC).
On top of this, No U-Turns (NUTS) offer:</p>
<ol class="simple">
<li><p><strong>Automatic Termination</strong>: NUTS introduces a criterion for automatically stopping the simulation of the Hamiltonian dynamics, preventing it from making U-turns, which is where its name comes from. This feature helps in dynamically determining the number of steps (steps in your HMC code) without manual tuning.</p></li>
<li><p><strong>Adaptive Step Size</strong>: While some HMC implementations might also adapt the step size, NUTS often includes sophisticated mechanisms for adjusting both the number of steps and the step size during the warm-up phase to optimize the exploration of the posterior distribution.</p></li>
<li><p><strong>Tree Building Process</strong>: NUTS uses a recursive tree-building process to explore the posterior distribution efficiently. This involves dynamically deciding how far to simulate the trajectory on each iteration, based on the geometry of the target distribution. A binary tree of potential states to explore is part of the mechanism that allows NUTS to decide when to stop extending the trajectory.</p></li>
</ol>
<hr class="docutils" />
<p>credits:</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "cfteach/BRDS_DATA644",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="Bayes_Factors.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Bayes Factors</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Gaussian_Processes.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Gaussian Processes</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Cristiano Fanelli<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>